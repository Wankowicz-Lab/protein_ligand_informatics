{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b61aa10c-b957-4ef6-aecb-3aaf4f767cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ending with 'qFit_sasa.csv' have been successfully transferred to the separate folder.\n",
      "SASA file check:   Residue Chain  Residue ID Atom Alt Loc  SASA Cleaned Base Name\n",
      "0     PRO     A           2    N          5.47              16gs\n",
      "1     PRO     A           2   CA          0.00              16gs\n",
      "2     PRO     A           2    C          0.00              16gs\n",
      "3     PRO     A           2    O          0.00              16gs\n",
      "4     PRO     A           2   CB          0.00              16gs\n",
      "5     PRO     A           2   CG          0.00              16gs\n",
      "6     PRO     A           2   CD          2.42              16gs\n",
      "7     TYR     A           3    N          0.00              16gs\n",
      "8     TYR     A           3   CA          0.00              16gs\n",
      "9     TYR     A           3    C          0.00              16gs\n",
      "Apo SASA:   Residue Chain  Residue ID Atom Alt Loc  SASA Cleaned Base Name\n",
      "0     PRO     A           2    N          5.47              16gs\n",
      "1     PRO     A           2   CA          0.00              16gs\n",
      "2     PRO     A           2    C          0.00              16gs\n",
      "3     PRO     A           2    O          0.00              16gs\n",
      "4     PRO     A           2   CB          0.00              16gs\n",
      "5     PRO     A           2   CG          0.00              16gs\n",
      "6     PRO     A           2   CD          2.42              16gs\n",
      "7     TYR     A           3    N          0.00              16gs\n",
      "8     TYR     A           3   CA          0.00              16gs\n",
      "9     TYR     A           3    C          0.00              16gs\n",
      "Holo SASA:      Residue Chain  Residue ID Atom Alt Loc  SASA Cleaned Base Name\n",
      "7041     PRO     A           2    N          3.28              19gs\n",
      "7042     PRO     A           2   CA          0.00              19gs\n",
      "7043     PRO     A           2    C          0.00              19gs\n",
      "7044     PRO     A           2    O          0.00              19gs\n",
      "7045     PRO     A           2   CB          0.00              19gs\n",
      "7046     PRO     A           2   CG          1.21              19gs\n",
      "7047     PRO     A           2   CD          6.04              19gs\n",
      "7048     TYR     A           3    N          0.00              19gs\n",
      "7049     TYR     A           3   CA          0.00              19gs\n",
      "7050     TYR     A           3    C          0.00              19gs\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate the Solvent accessible surface area (sasa) files from dataset, concatenate all sasa dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/qFit_sasa_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with qFit_sasa.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_qFit_sasa.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with 'qFit_sasa.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/qFit_sasa_files/qFit_sasa_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_qFit_sasa', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        sasa_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        sasa_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(sasa_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_sasa_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_sasa_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/qFit_sasa_files/qFit_sasa_files/combined_sasa_df.csv', index=False)\n",
    "print(\"SASA file check:\", combined_sasa_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined SASA dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_sasa_aligned = combined_sasa_df[combined_sasa_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_sasa_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_sasa_aligned.csv',index=False)\n",
    "print(\"Apo SASA:\", apo_sasa_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_sasa_aligned = combined_sasa_df[combined_sasa_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_sasa_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_sasa_aligned.csv',index=False)\n",
    "print(\"Holo SASA:\", holo_sasa_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b90e0-6d5a-4f55-bf7d-d8b3527caf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate the solvent accessible surface area (sasa) of residues within 5.0 Angstroms of the binding site files from dataset, concatenate all sasa 5.0 dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_sasa_subset_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with qFit_sasa.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_sasa_subset.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_sasa_subset.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# How to add the PDB variable to each 5_sasa_subset file then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_sasa_subset_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_5.0_sasa_subset', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        _5_sasa_subset_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        _5_sasa_subset_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(_5_sasa_subset_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_5_sasa_subset_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_5_sasa_subset_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_sasa_subset_files/combined_5_sasa_subset_df.csv', index=False)\n",
    "print(\"SASA_5.0 file check:\", combined_5_sasa_subset_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_5_sasa_subset_aligned = combined_5_sasa_subset_df[combined_5_sasa_subset_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_5_sasa_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_sasa_subset_aligned.csv',index=False)\n",
    "print(\"Apo SASA 5.0:\",apo_5_sasa_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_5_sasa_subset_aligned = combined_5_sasa_subset_df[combined_5_sasa_subset_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_5_sasa_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_5_sasa_subset_aligned.csv',index=False)\n",
    "print(\"Holo SASA 5.0:\", holo_5_sasa_subset_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b363f439-49b7-4c7d-b254-c12da1546ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ending with 'qFit_hbonds.csv' have been successfully transferred to the separate folder.\n",
      "Hbond file check:   donor_chain  donor_residue_number donor_residue_name donor_atom  \\\n",
      "0           A                     3                TYR          N   \n",
      "1           A                     4                THR          N   \n",
      "2           A                     5                VAL          N   \n",
      "3           A                     6                VAL          N   \n",
      "4           A                     7                TYR          N   \n",
      "5           A                    10                VAL          N   \n",
      "6           A                    11                ARG          N   \n",
      "7           A                    11                ARG         NE   \n",
      "8           A                    11                ARG        NH1   \n",
      "9           A                    11                ARG        NH1   \n",
      "\n",
      "  donor_altloc  donor_occupancy  donor_bfactor hydrogen_atom acceptor_chain  \\\n",
      "0                           1.0          19.93             H              S   \n",
      "1                           1.0          19.11             H              A   \n",
      "2                           1.0          18.34             H              A   \n",
      "3                           1.0          18.56             H              A   \n",
      "4                           1.0          21.68             H              A   \n",
      "5                           1.0          20.37             H              A   \n",
      "6                           1.0          19.82             H              A   \n",
      "7                           1.0          21.10            HE              A   \n",
      "8                           1.0          20.57          HH12              A   \n",
      "9                           1.0          20.57          HH12              A   \n",
      "\n",
      "   acceptor_residue_number acceptor_residue_name acceptor_atom  \\\n",
      "0                      610                   HOH             O   \n",
      "1                       56                   GLN             O   \n",
      "2                       29                   LYS             O   \n",
      "3                       54                   LYS             O   \n",
      "4                       31                   GLU             O   \n",
      "5                        8                   PHE             O   \n",
      "6                      202                   PRO             O   \n",
      "7                      198                   TYR             O   \n",
      "8                      249                   HOH             O   \n",
      "9                      337                   HOH             O   \n",
      "\n",
      "  acceptor_altloc  acceptor_occupancy  acceptor_bfactor  distance       angle  \\\n",
      "0                                0.49             21.61  3.246714  156.631330   \n",
      "1                                1.00             17.76  3.010656  154.189905   \n",
      "2                                1.00             21.83  2.720746  162.774400   \n",
      "3                                1.00             20.05  2.842607  167.315683   \n",
      "4                                1.00             22.17  3.034419  155.668993   \n",
      "5                                1.00             20.66  2.807531  138.912193   \n",
      "6                                1.00             18.79  2.902556  165.842699   \n",
      "7                                1.00             18.59  3.016104  155.536478   \n",
      "8                                0.65             21.78  2.838421  168.689162   \n",
      "9                                0.75             22.40  3.529369  126.391327   \n",
      "\n",
      "  Cleaned Base Name  \n",
      "0              16gs  \n",
      "1              16gs  \n",
      "2              16gs  \n",
      "3              16gs  \n",
      "4              16gs  \n",
      "5              16gs  \n",
      "6              16gs  \n",
      "7              16gs  \n",
      "8              16gs  \n",
      "9              16gs  \n",
      "Apo Hbonds:   donor_chain  donor_residue_number donor_residue_name donor_atom  \\\n",
      "0           A                     3                TYR          N   \n",
      "1           A                     4                THR          N   \n",
      "2           A                     5                VAL          N   \n",
      "3           A                     6                VAL          N   \n",
      "4           A                     7                TYR          N   \n",
      "5           A                    10                VAL          N   \n",
      "6           A                    11                ARG          N   \n",
      "7           A                    11                ARG         NE   \n",
      "8           A                    11                ARG        NH1   \n",
      "9           A                    11                ARG        NH1   \n",
      "\n",
      "  donor_altloc  donor_occupancy  donor_bfactor hydrogen_atom acceptor_chain  \\\n",
      "0                           1.0          19.93             H              S   \n",
      "1                           1.0          19.11             H              A   \n",
      "2                           1.0          18.34             H              A   \n",
      "3                           1.0          18.56             H              A   \n",
      "4                           1.0          21.68             H              A   \n",
      "5                           1.0          20.37             H              A   \n",
      "6                           1.0          19.82             H              A   \n",
      "7                           1.0          21.10            HE              A   \n",
      "8                           1.0          20.57          HH12              A   \n",
      "9                           1.0          20.57          HH12              A   \n",
      "\n",
      "   acceptor_residue_number acceptor_residue_name acceptor_atom  \\\n",
      "0                      610                   HOH             O   \n",
      "1                       56                   GLN             O   \n",
      "2                       29                   LYS             O   \n",
      "3                       54                   LYS             O   \n",
      "4                       31                   GLU             O   \n",
      "5                        8                   PHE             O   \n",
      "6                      202                   PRO             O   \n",
      "7                      198                   TYR             O   \n",
      "8                      249                   HOH             O   \n",
      "9                      337                   HOH             O   \n",
      "\n",
      "  acceptor_altloc  acceptor_occupancy  acceptor_bfactor  distance       angle  \\\n",
      "0                                0.49             21.61  3.246714  156.631330   \n",
      "1                                1.00             17.76  3.010656  154.189905   \n",
      "2                                1.00             21.83  2.720746  162.774400   \n",
      "3                                1.00             20.05  2.842607  167.315683   \n",
      "4                                1.00             22.17  3.034419  155.668993   \n",
      "5                                1.00             20.66  2.807531  138.912193   \n",
      "6                                1.00             18.79  2.902556  165.842699   \n",
      "7                                1.00             18.59  3.016104  155.536478   \n",
      "8                                0.65             21.78  2.838421  168.689162   \n",
      "9                                0.75             22.40  3.529369  126.391327   \n",
      "\n",
      "  Cleaned Base Name  \n",
      "0              16gs  \n",
      "1              16gs  \n",
      "2              16gs  \n",
      "3              16gs  \n",
      "4              16gs  \n",
      "5              16gs  \n",
      "6              16gs  \n",
      "7              16gs  \n",
      "8              16gs  \n",
      "9              16gs  \n",
      "Holo Hbonds:     donor_chain  donor_residue_number donor_residue_name donor_atom  \\\n",
      "939           A                     3                TYR          N   \n",
      "940           A                     4                THR          N   \n",
      "941           A                     4                THR        OG1   \n",
      "942           A                     5                VAL          N   \n",
      "943           A                     6                VAL          N   \n",
      "944           A                     7                TYR          N   \n",
      "945           A                     7                TYR          N   \n",
      "946           A                     7                TYR         OH   \n",
      "947           A                    11                ARG          N   \n",
      "948           A                    11                ARG         NE   \n",
      "\n",
      "    donor_altloc  donor_occupancy  donor_bfactor hydrogen_atom acceptor_chain  \\\n",
      "939                           1.0          15.70             H              S   \n",
      "940                           1.0          11.36             H              A   \n",
      "941                           1.0          15.99           HG1              A   \n",
      "942                           1.0          12.80             H              A   \n",
      "943                           1.0          10.11             H              A   \n",
      "944                           1.0          11.04             H              A   \n",
      "945                           1.0          11.04             H              A   \n",
      "946                           1.0          10.81            HH              A   \n",
      "947                           1.0          13.04             H              A   \n",
      "948                           1.0          20.04            HE              A   \n",
      "\n",
      "     acceptor_residue_number acceptor_residue_name acceptor_atom  \\\n",
      "939                      454                   HOH             O   \n",
      "940                       56                   GLN             O   \n",
      "941                      278                   HOH             O   \n",
      "942                       29                   LYS             O   \n",
      "943                       54                   LYS             O   \n",
      "944                      232                   HOH             O   \n",
      "945                       31                   GLU             O   \n",
      "946                      211                   GSH           SG2   \n",
      "947                      202                   PRO             O   \n",
      "948                      198                   TYR             O   \n",
      "\n",
      "    acceptor_altloc  acceptor_occupancy  acceptor_bfactor  distance  \\\n",
      "939                                0.52             18.19  3.166773   \n",
      "940                                1.00             11.74  2.972672   \n",
      "941                                1.00             20.06  2.758050   \n",
      "942                                1.00             14.76  2.840768   \n",
      "943                                1.00             11.77  2.819875   \n",
      "944                                1.00             15.70  3.487827   \n",
      "945                                1.00             15.41  3.128585   \n",
      "946                                0.61             33.87  2.702786   \n",
      "947                                1.00             11.64  2.924473   \n",
      "948                                1.00             13.15  2.947041   \n",
      "\n",
      "          angle Cleaned Base Name  \n",
      "939  161.550341              19gs  \n",
      "940  154.292847              19gs  \n",
      "941  150.856449              19gs  \n",
      "942  156.108493              19gs  \n",
      "943  172.292285              19gs  \n",
      "944  123.918721              19gs  \n",
      "945  154.599528              19gs  \n",
      "946  131.080176              19gs  \n",
      "947  164.979621              19gs  \n",
      "948  148.706424              19gs  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate qFit H-bond files from dataset, concatenate all H-bond dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/qFit_hbond_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with qFit_hbonds.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_qFit_hbonds.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with 'qFit_hbonds.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/qFit_hbond_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_qFit_hbonds', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        hbonds_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        hbonds_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(hbonds_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_hbonds_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_hbonds_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/qFit_hbond_files/combined_sasa_df.csv', index=False)\n",
    "print(\"Hbond file check:\", combined_hbonds_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined qFit_hbond dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_hbonds_aligned = combined_hbonds_df[combined_hbonds_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_hbonds_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_hbonds_aligned.csv',index=False)\n",
    "print(\"Apo Hbonds:\", apo_hbonds_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_hbonds_aligned = combined_hbonds_df[combined_hbonds_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_hbonds_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_hbonds_aligned.csv',index=False)\n",
    "print(\"Holo Hbonds:\", holo_hbonds_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4bfdd-7cd0-4c2b-8f79-a3a370c440bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate the h-bonds of residues within 5.0 Angstroms of the binding site files from dataset, concatenate all h-bond 5.0 dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_hbond_subset_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with 5.0 hbond subset.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_hbond_subset.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_hbond_subset.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# How to add the PDB variable to each 5_hbond_subset file then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_hbond_subset_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_5.0_hbond_subset', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        _5_hbond_subset_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        _5_hbond_subset_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(_5_hbond_subset_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_5_hbond_subset_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_5_hbond_subset_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_hbond_subset_files/combined_5_hbond_subset_df.csv', index=False)\n",
    "print(\"Hbond_5.0 file check:\", combined_5_hbond_subset_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_5_hbond_subset_aligned = combined_5_hbond_subset_df[combined_5_hbond_subset_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_5_hbond_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_hbond_subset_aligned.csv',index=False)\n",
    "print(\"Apo Hbond 5.0:\", apo_5_hbond_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_5_hbond_subset_aligned = combined_5_hbond_subset_df[combined_5_hbond_subset_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_5_hbond_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_5_hbond_subset_aligned.csv',index=False)\n",
    "print(\"Holo Hbond 5.0:\", holo_5_hbond_subset_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a4a497-f1f4-4a97-b945-86ca6cc743fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This line of code is to concatanate all B-factor values of residues then define a subset of B-factor residues within 5.0 Angstroms of the binding site files from dataset, and transfer all of those into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Use glob to find all *_B_factors.csv files in the specified directory\n",
    "b_factor_files = glob.glob(os.path.join('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241014T184131Z-001/full_protein', '*_B_factors.csv'))\n",
    "\n",
    "# Initialize a list to store the DataFrames\n",
    "b_factor_dfs = []\n",
    "\n",
    "# Loop through each file and read it into a DataFrame\n",
    "for file in b_factor_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Optionally, add a new column to identify the source file\n",
    "    b_factor_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_b_factor_df = pd.concat(b_factor_dfs, ignore_index=True)\n",
    "combined_b_factor_df['chain'] = combined_b_factor_df['chain'].str.replace(r\"[\\[\\]']+\", '', regex=True).str.strip()\n",
    "combined_b_factor_df['resn'] = combined_b_factor_df['resn'].str.replace(r\"[\\[\\]']+\", '', regex=True).str.strip()\n",
    "\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_b_factor_df.head(10))\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with 5.0 Bfactor.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_bfactor_subset.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_bfactor_subset.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_5.0_bfactor_subset', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        _5_bfactor_subset_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        _5_bfactor_subset_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(_5_bfactor_subset_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_5_bfactor_subset_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_5_bfactor_subset_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files/combined_5_bfactor_subset_df.csv', index=False)\n",
    "print(\"Bfactor_5.0 file check:\",combined_5_bfactor_subset_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_5_bfactor_subset_aligned = combined_5_bfactor_subset_df[combined_5_bfactor_subset_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_5_bfactor_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_bfactor_subset_aligned.csv',index=False)\n",
    "print(\"Apo B-factor 5.0:\", apo_5_bfactor_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_5_bfactor_subset_aligned = combined_5_bfactor_subset_df[combined_5_bfactor_subset_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_5_bfactor_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_5_bfactor_subset_aligned.csv',index=False)\n",
    "print(\"Holo B-factor 5.0:\", holo_5_bfactor_subset_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83799f61-14d4-4957-98d6-cade31de0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OP data Conversion complete!\n",
      "The combined dataset has been successfully saved to 'combined_dataset.csv'.\n",
      "Apo OP:      s2calc   s2ortho  s2ang resn  resi chain Cleaned Base Name\n",
      "0  0.900755  0.900755    1.0  TYR     3     A              16gs\n",
      "1  0.869301  0.869301    1.0  THR     4     A              16gs\n",
      "2  0.920219  0.920219    1.0  VAL     5     A              16gs\n",
      "3  0.861086  0.861086    1.0  VAL     6     A              16gs\n",
      "4  0.878256  0.878256    1.0  TYR     7     A              16gs\n",
      "5  0.807282  0.807282    1.0  PHE     8     A              16gs\n",
      "6  0.858570  0.858570    1.0  VAL    10     A              16gs\n",
      "7  0.919997  0.919997    1.0  ARG    11     A              16gs\n",
      "8  0.894316  0.894316    1.0  ARG    13     A              16gs\n",
      "9  0.923697  0.923697    1.0  CYS    14     A              16gs\n",
      "Holo OP:         s2calc   s2ortho  s2ang resn  resi chain Cleaned Base Name\n",
      "1248  0.894108  0.894108    1.0  TYR     3     A              19gs\n",
      "1249  0.861579  0.861579    1.0  THR     4     A              19gs\n",
      "1250  0.778278  0.778278    1.0  VAL     5     A              19gs\n",
      "1251  0.919494  0.919494    1.0  VAL     6     A              19gs\n",
      "1252  0.909634  0.909634    1.0  TYR     7     A              19gs\n",
      "1253  0.818259  0.818259    1.0  PHE     8     A              19gs\n",
      "1254  0.805838  0.805838    1.0  VAL    10     A              19gs\n",
      "1255  0.933080  0.933080    1.0  ARG    11     A              19gs\n",
      "1256  0.920348  0.920348    1.0  ARG    13     A              19gs\n",
      "1257  0.927102  0.927102    1.0  CYS    14     A              19gs\n",
      "Files ending with '5.0_order_param_subset.csv' have been successfully transferred to the separate folder.\n",
      "Order Parameter_5.0 file check:      s2calc   s2ortho  s2ang resn resi chain Cleaned Base Name\n",
      "0  0.878256  0.878256    1.0  TYR    7     A              16gs\n",
      "1  0.807282  0.807282    1.0  PHE    8     A              16gs\n",
      "2  0.858570  0.858570    1.0  VAL   10     A              16gs\n",
      "3  0.894316  0.894316    1.0  ARG   13     A              16gs\n",
      "4  0.468769  0.468769    1.0  TRP   38     A              16gs\n",
      "5  0.566755  0.566755    1.0  LYS   44     A              16gs\n",
      "6  0.726539  0.726539    1.0  GLN   51     A              16gs\n",
      "7  0.788706  0.788706    1.0  LEU   52     A              16gs\n",
      "8  0.902827  0.902827    1.0  GLN   64     A              16gs\n",
      "9  0.915261  0.915261    1.0  SER   65     A              16gs\n",
      "Apo OP 5.0:      s2calc   s2ortho  s2ang resn resi chain Cleaned Base Name\n",
      "0  0.878256  0.878256    1.0  TYR    7     A              16gs\n",
      "1  0.807282  0.807282    1.0  PHE    8     A              16gs\n",
      "2  0.858570  0.858570    1.0  VAL   10     A              16gs\n",
      "3  0.894316  0.894316    1.0  ARG   13     A              16gs\n",
      "4  0.468769  0.468769    1.0  TRP   38     A              16gs\n",
      "5  0.566755  0.566755    1.0  LYS   44     A              16gs\n",
      "6  0.726539  0.726539    1.0  GLN   51     A              16gs\n",
      "7  0.788706  0.788706    1.0  LEU   52     A              16gs\n",
      "8  0.902827  0.902827    1.0  GLN   64     A              16gs\n",
      "9  0.915261  0.915261    1.0  SER   65     A              16gs\n",
      "Holo OP 5.0:       s2calc   s2ortho  s2ang resn resi chain Cleaned Base Name\n",
      "15  0.909634  0.909634    1.0  TYR    7     A              19gs\n",
      "16  0.818259  0.818259    1.0  PHE    8     A              19gs\n",
      "17  0.805838  0.805838    1.0  VAL   10     A              19gs\n",
      "18  0.920348  0.920348    1.0  ARG   13     A              19gs\n",
      "19  0.370158  0.370158    1.0  VAL   35     A              19gs\n",
      "20  0.669203  0.669203    1.0  TRP   38     A              19gs\n",
      "21  0.464017  0.464017    1.0  GLN   39     A              19gs\n",
      "22  0.750640  0.750640    1.0  GLN   51     A              19gs\n",
      "23  0.809720  0.809720    1.0  ILE  104     A              19gs\n",
      "24  0.728981  0.728981    1.0  TYR  108     A              19gs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harrw10\\AppData\\Local\\Temp\\ipykernel_40560\\186021971.py:132: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_5_op_subset_df = pd.concat(dataframes_2_, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "This line of code is to transfer and combine the  the Order Parameter dataset to my documents, separate the Order Parameter residues within 5.0 Angstroms of the binding site from the dataset, concatenate all Order Parameter 5.0 dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mplcursors\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "#How to convert all .out files from desktop to .csv\n",
    "#Directory containing the .out files (Desktop directory)\n",
    "directory = \"/Users/harrw10/Desktop/op_data\"\n",
    "#Loop through all .out files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".out\"):\n",
    "        # Read the content of the .out file\n",
    "        with open(os.path.join(directory, filename), 'r') as infile:\n",
    "            content = infile.read()\n",
    "        \n",
    "        # Define the output .csv file name\n",
    "        csv_filename = filename.replace(\".out\", \".csv\")\n",
    "        \n",
    "        # Write the content to the .csv file\n",
    "        with open(os.path.join(directory, csv_filename), 'w') as outfile:\n",
    "            outfile.write(content)\n",
    "\n",
    "print(\"OP data Conversion complete!\")\n",
    "\n",
    "#Adding PDB name to a column in each of the op files then create a single combined file\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/Desktop/op_data'\n",
    "\n",
    "#Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "#List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove '_OP'\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_OP', '')\n",
    "        \n",
    "        # Read the csv file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "#Concatenate all dataframes in the list into a single dataframe\n",
    "combined_op_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#Save the combined dataframe to a new csv file\n",
    "combined_op_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/op_subset_files/op_combined.csv', index=False)\n",
    "\n",
    "print(\"The combined dataset has been successfully saved to 'combined_dataset.csv'.\")\n",
    "\n",
    "#How to combine aspects of the 'Apo' data and OP_subset into a singular file\n",
    "#Define the dataframe for the op data and apo specific proteins\n",
    "combined_op_df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/op_subset_files/op_combined.csv')\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_op_subset_aligned = combined_op_df[combined_op_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_op_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_op_subset_aligned.csv',index=False)\n",
    "print(\"Apo OP:\", apo_op_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_op_subset_aligned = combined_op_df[combined_op_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_op_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_op_subset_aligned.csv',index=False)\n",
    "print(\"Holo OP:\", holo_op_subset_aligned.head(10))\n",
    "\n",
    "#How to separate the _5.0_order_param_subset files from the entire data set and transfer them into an individual folder\n",
    "#Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_op_subset_files/'\n",
    "\n",
    "#Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "#List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "#Loop through each file and transfer files ending with qFit_sasa.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_order_param_subset.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_order_param_subset.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "#How to add the PDB variable to each 5_order_param_subset file then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "#Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_op_subset_files'\n",
    "\n",
    "#Initialize an empty list to hold the dataframes\n",
    "dataframes_2_ = []\n",
    "\n",
    "#List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_5.0_order_param_subset', '')\n",
    "     #Read the csv file into a dataframe\n",
    "        _5_op_subset_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        #Add a new column with the cleaned base name\n",
    "        _5_op_subset_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        #Append the dataframe to the list\n",
    "        dataframes_2_.append(_5_op_subset_df)\n",
    "#Concatenate all dataframes in the list into a single dataframe\n",
    "combined_5_op_subset_df = pd.concat(dataframes_2_, ignore_index=True)  \n",
    "combined_5_op_subset_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_op_subset_files/combined_5_op_subset_df.csv', index=False)\n",
    "print(\"Order Parameter_5.0 file check:\",combined_5_op_subset_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df_2 = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df_2():\n",
    "    apo_df_2 = df_2[df_2['Apo'].notna() & (df_2['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns_2 = ['Apo']\n",
    "    apo_df_2 = apo_df_2[apo_columns_2]\n",
    "    return apo_df_2\n",
    "apo_data_2 = apo_df_2()\n",
    "\n",
    "apo_5_op_subset_aligned = combined_5_op_subset_df[combined_5_op_subset_df['Cleaned Base Name'] .isin (apo_data_2['Apo'])]\n",
    "apo_5_op_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_op_subset_aligned.csv',index=False)\n",
    "print(\"Apo OP 5.0:\", apo_5_op_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df_2():\n",
    "    holo_df_2 = df_2[df_2['Holo'].notna() & (df_2['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns_2 = ['Holo']\n",
    "    holo_df_2 = holo_df_2[holo_columns_2]\n",
    "    return holo_df_2\n",
    "holo_data_2 = holo_df_2()\n",
    "\n",
    "holo_5_op_subset_aligned = combined_5_op_subset_df[combined_5_op_subset_df['Cleaned Base Name'] .isin (holo_data_2['Holo'])]\n",
    "holo_5_op_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_5_op_subset_aligned.csv',index=False)\n",
    "print(\"Holo OP 5.0:\", holo_5_op_subset_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c1d30-040a-42f7-afb9-37148bc73e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate r-value files from dataset, concatenate all r-value dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/rvalues_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with rvalues.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_rvalues.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with 'rvalues.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# How to add the PDB variable to each rvalues file then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "# Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/rvalues_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_rvalues', '')\n",
    "     # Read the csv file into a dataframe\n",
    "        rvalues_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Add a new column with the cleaned base name\n",
    "        rvalues_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(rvalues_df)\n",
    "# Concatenate all dataframes in the list into a single dataframe\n",
    "combined_rvalues_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_rvalues_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/rvalues_files/combined_rvalues_df.csv', index=False)\n",
    "print(\"rvalue file check:\", combined_rvalues_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined rvalues dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_rvalues_aligned = combined_rvalues_df[combined_rvalues_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_rvalues_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_rvalues_aligned.csv',index=False)\n",
    "print(\"Apo rvalues:\", apo_rvalues_aligned.head(10))\n",
    "\n",
    "# Define criteria for Holo structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_rvalues_aligned = combined_rvalues_df[combined_rvalues_df['Cleaned Base Name'] .isin (holo_data['Holo'])]\n",
    "holo_rvalues_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_rvalues_aligned.csv',index=False)\n",
    "print(\"Holo rvalues:\", holo_rvalues_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98fa64c4-bab7-435b-9583-e2e61382676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files ending with '5.0_closeres.csv' have been successfully transferred to the separate folder.\n",
      "    resi chain   PDB  distance\n",
      "0     51     A  19gs  2.398891\n",
      "1    413     S  19gs  2.762175\n",
      "2   1356     S  19gs  3.776991\n",
      "3   1484     S  19gs  4.085050\n",
      "4    621     S  19gs  4.419173\n",
      "..   ...   ...   ...       ...\n",
      "95   235     A  1c27  2.905827\n",
      "96   132     B  1d4h  2.694492\n",
      "97    82     A  1d4h  2.840231\n",
      "98   919     S  1d4h  3.164080\n",
      "99   176     B  1d4h  3.093016\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "Apo closeres 5.0: Empty DataFrame\n",
      "Columns: [resi, chain, PDB, distance]\n",
      "Index: []\n",
      "Holo closeres 5.0:    resi chain   PDB  distance\n",
      "0    51     A  19gs  2.398891\n",
      "1   413     S  19gs  2.762175\n",
      "2  1356     S  19gs  3.776991\n",
      "3  1484     S  19gs  4.085050\n",
      "4   621     S  19gs  4.419173\n",
      "5  1563     S  19gs  4.073359\n",
      "6   108     A  19gs  2.877991\n",
      "7    38     A  19gs  3.003979\n",
      "8  1399     S  19gs  2.914223\n",
      "9     8     A  19gs  3.305551\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "This line of code is to separate the 5.0 closeres files from dataset, concatenate all dataframes into a single dataframe\n",
    "and specify for only the 'Apo' & 'Holo' structures\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_closeres_subset_files/'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "# List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "# Loop through each file and transfer files ending with qFit_sasa.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_closeres.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_closeres.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "# Define the directory\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_closeres_subset_files'\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        pdb_id = filename.split('_')[0]\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        # Modify the 'PDB' column if it exists\n",
    "        if 'PDB' in df.columns:\n",
    "            df['PDB'] = df['PDB'].str.replace('_qFit', '', regex=False)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into a single dataframe    \n",
    "combined_5_closeres_df = pd.concat(dataframes, ignore_index=True)  \n",
    "# Remove any remaining duplicates\n",
    "combined_5_closeres_df = combined_5_closeres_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(\"Combined closeres files check:\", combined_5_closeres_df.head(10))\n",
    "\n",
    "# How to separate all Apo/Holo structures from the combined dataframe\n",
    "# Load the apo/holo template into a dataframe\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "# Define criteria for Apo structure\n",
    "def apo_df():\n",
    "    apo_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "# Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    apo_df = apo_df[apo_columns]\n",
    "    return apo_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_5_closeres_subset_aligned = combined_5_closeres_df[combined_5_closeres_df['PDB'] .isin (apo_data['Apo'])]\n",
    "apo_5_closeres_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_closeres_subset_aligned.csv',index=False)\n",
    "print(\"Apo closeres 5.0:\", apo_5_closeres_subset_aligned.head(10))\n",
    "\n",
    "# Define criteria for holo_res structure\n",
    "def holo_df():\n",
    "    holo_df = df[df['Holo'].notna() & (df['Holo'] != '')]\n",
    "# Select only the desired columns\n",
    "    holo_columns = ['Holo']\n",
    "    holo_df = holo_df[holo_columns]\n",
    "    return holo_df\n",
    "holo_data = holo_df()\n",
    "\n",
    "holo_5_closeres_subset_aligned = combined_5_closeres_df[combined_5_closeres_df['PDB'] .isin (holo_data['Holo'])]\n",
    "holo_5_closeres_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/holo_5_closeres_subset_aligned.csv',index=False)\n",
    "\n",
    "print(\"Holo closeres 5.0:\", holo_5_closeres_subset_aligned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f86f5c-92a6-4f3f-a7ce-ee4db1e2c128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
